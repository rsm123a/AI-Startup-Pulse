{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f777ce01-a8d8-4247-9599-08be07e3c29c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"structured_data\":516},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766940830133}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import json\n",
    "\n",
    "# 1. Access the Databricks Foundation Model (Llama 3 or similar)\n",
    "# Note: This syntax works on most modern Databricks Workspaces\n",
    "def extract_startup_info(raw_text):\n",
    "    # We tell the AI exactly where to look and what to ignore\n",
    "    prompt = f\"\"\"\n",
    "    SYSTEM: You are a data extractor. You will be provided with a Wikipedia article.\n",
    "    IMPORTANT: Ignore any text about 'donations', 'fundraising', or 'Wikipedia is free'.\n",
    "    \n",
    "    Look specifically for the 'Infobox' section (usually at the start of the article) \n",
    "    to find company details.\n",
    "    \n",
    "    Return a JSON object for:\n",
    "    - company_name\n",
    "    - founding_year\n",
    "    - top_products (list the main software or AI models mentioned)\n",
    "\n",
    "    RAW TEXT:\n",
    "    {raw_text[:6000]}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        import mlflow.deployments\n",
    "        client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "        \n",
    "        response = client.predict(\n",
    "            endpoint=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "            inputs={\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "        )\n",
    "        \n",
    "        # Access the dictionary response\n",
    "        content = response['choices'][0]['message']['content']\n",
    "        \n",
    "        # Simple cleanup: if the AI includes markdown backticks like ```json, strip them\n",
    "        clean_json = content.replace('```json', '').replace('```', '').strip()\n",
    "        return clean_json\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# 2. Apply it to your Bronze Table\n",
    "ai_udf = udf(extract_startup_info, StringType())\n",
    "\n",
    "silver_df = spark.table(\"bronze.raw_web_data\") \\\n",
    "    .withColumn(\"structured_data\", ai_udf(col(\"raw_markdown\")))\n",
    "\n",
    "# 3. Save to Silver\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.startup_fundamentals\")\n",
    "\n",
    "display(spark.table(\"silver.startup_fundamentals\").select(\"startup_name\", \"structured_data\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_ai_extraction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
